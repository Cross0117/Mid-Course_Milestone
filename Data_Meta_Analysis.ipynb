{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd772f5a",
   "metadata": {},
   "source": [
    "# 🧙‍♂️ D&D Meta Analysis (Mid-Course Milestone)\n",
    "\n",
    "**Goal:** demonstrate the full data analysis workflow (load → inspect → clean → explore → visualize).\n",
    "\n",
    "**Dataset:** `Data/dnd_classes_races_starter.csv` (hand-curated for this project; see citations below).\n",
    "\n",
    "**Outputs in this notebook**\n",
    "- Inspection: `.head()`, `.info()`, `.describe()`, missing values, duplicates  \n",
    "- Cleaning: normalize casing, convert hit dice to numbers, map tier/popularity, drop dupes  \n",
    "- EDA: counts, grouped summaries  \n",
    "- Visuals: class bar chart, race pie chart, race × class heatmap  \n",
    "- Derived table: race × class matrix (pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d82b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# show plots inline\n",
    "%matplotlib inline\n",
    "\n",
    "# project paths\n",
    "BASE = Path().resolve()\n",
    "DATA = (BASE / \"Data\")\n",
    "DATA.mkdir(exist_ok=True)\n",
    "\n",
    "CSV_IN      = DATA / \"dnd_classes_races_starter.csv\"\n",
    "CLEAN_CSV   = DATA / \"dnd_classes_races_clean.csv\"\n",
    "MATRIX_CSV  = DATA / \"race_class_matrix.csv\"\n",
    "CLASS_BAR   = DATA / \"class_counts.png\"\n",
    "RACE_PIE    = DATA / \"race_pie.png\"\n",
    "HEATMAP_PNG = DATA / \"race_class_heatmap.png\"\n",
    "SESSIONS    = DATA / \"sessions_log.csv\"\n",
    "\n",
    "CSV_IN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28f9c60",
   "metadata": {},
   "source": [
    "## 1) Load data\n",
    "If the CSV is missing, the notebook will raise an error. We’ll work from the `Data/` folder for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8910d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CSV_IN.exists():\n",
    "    raise FileNotFoundError(f\"Missing dataset: {CSV_IN} — place your CSV in the Data/ folder.\")\n",
    "\n",
    "df = pd.read_csv(CSV_IN)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc57f92d",
   "metadata": {},
   "source": [
    "## 2) Initial inspection\n",
    "We check structure, types, basic stats, missingness, and duplicates to identify cleaning targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e6effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.info())            # structure & dtypes\n",
    "display(df.describe(include=\"all\"))  # summary stats incl. categoricals\n",
    "display(df.isna().sum().rename(\"MissingValues\"))\n",
    "display(pd.Series({\"DuplicateRows\": int(df.duplicated().sum())}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a369dc9",
   "metadata": {},
   "source": [
    "### Cleaning plan (based on inspection)\n",
    "- Normalize **Race/Class/Subclass** casing to Title Case  \n",
    "- Convert `'Hit Die'` strings like `d8` → numeric 8  \n",
    "- Map **Tier (Power Level)** to ordinal (Low=1, Mid=2, High=3)  \n",
    "- Map **Popularity** to ordinal (Low=1, Medium=2, High=3)  \n",
    "- Drop exact duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e374860",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()\n",
    "\n",
    "# normalize key categoricals\n",
    "for col in (\"Race\", \"Class\", \"Subclass\"):\n",
    "    if col in df_clean.columns:\n",
    "        df_clean[col] = df_clean[col].astype(str).str.strip().str.title()\n",
    "\n",
    "# convert Hit Die 'd8' -> 8\n",
    "if \"Hit Die\" in df_clean.columns:\n",
    "    num = (\n",
    "        df_clean[\"Hit Die\"]\n",
    "        .astype(str).str.strip().str.lower().str.replace(\"d\", \"\", regex=False)\n",
    "    )\n",
    "    df_clean[\"HitDieNum\"] = pd.to_numeric(num, errors=\"coerce\")\n",
    "\n",
    "# map Tier/Popularity to ordered integers\n",
    "if \"Tier (Power Level)\" in df_clean.columns:\n",
    "    df_clean[\"TierNum\"] = df_clean[\"Tier (Power Level)\"].map({\"Low\": 1, \"Mid\": 2, \"High\": 3})\n",
    "\n",
    "if \"Popularity\" in df_clean.columns:\n",
    "    df_clean[\"PopularityScore\"] = df_clean[\"Popularity\"].map({\"Low\": 1, \"Medium\": 2, \"High\": 3})\n",
    "\n",
    "# drop exact duplicates\n",
    "before = len(df_clean)\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "removed = before - len(df_clean)\n",
    "\n",
    "removed, df_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75ef4ad",
   "metadata": {},
   "source": [
    "### Save the cleaned dataset (reproducibility)\n",
    "This creates `Data/dnd_classes_races_clean.csv` so results are reproducible outside the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6acf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv(CLEAN_CSV, index=False)\n",
    "CLEAN_CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f63f05",
   "metadata": {},
   "source": [
    "## 3) Exploratory Data Analysis (EDA)\n",
    "Counts and quick groupings to understand distribution and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99149312",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df_clean[\"Class\"].value_counts().sort_values(ascending=False)\n",
    "race_counts  = df_clean[\"Race\"].value_counts().sort_values(ascending=False)\n",
    "\n",
    "display(class_counts.rename(\"ClassCount\"))\n",
    "display(race_counts.rename(\"RaceCount\"))\n",
    "\n",
    "# optional: average numeric columns by class/race (if present)\n",
    "summary_cols = [c for c in (\"HitDieNum\", \"TierNum\", \"PopularityScore\") if c in df_clean.columns]\n",
    "if summary_cols:\n",
    "    display(df_clean.groupby(\"Class\")[summary_cols].mean().round(2).sort_index())\n",
    "    display(df_clean.groupby(\"Race\")[summary_cols].mean().round(2).sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5533e2ab",
   "metadata": {},
   "source": [
    "## 4) Race × Class matrix (pivot)\n",
    "This shows how many entries exist for each Race–Class combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8522c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = pd.pivot_table(\n",
    "    df_clean,\n",
    "    index=\"Race\",\n",
    "    columns=\"Class\",\n",
    "    values=\"Subclass\",  # any non-null column will do\n",
    "    aggfunc=\"count\",\n",
    "    fill_value=0\n",
    ").sort_index().reindex(sorted(df_clean[\"Class\"].dropna().str.title().unique()), axis=1)\n",
    "\n",
    "combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa25303",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo.to_csv(MATRIX_CSV)\n",
    "MATRIX_CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3700805e",
   "metadata": {},
   "source": [
    "## 5) Visualizations\n",
    "Bar chart (classes), pie chart (races), and heatmap (Race × Class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1048eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = class_counts.plot(kind=\"bar\", title=\"Class Counts\")\n",
    "ax.set_xlabel(\"Class\"); ax.set_ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(CLASS_BAR)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d66add",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = race_counts.plot(kind=\"pie\", autopct=\"%1.1f%%\", title=\"Race Distribution\", ylabel=\"\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(RACE_PIE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4345d146",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.5, 4.5))\n",
    "ax = plt.gca()\n",
    "im = ax.imshow(combo, aspect=\"auto\")\n",
    "ax.set_xticks(range(len(combo.columns)))\n",
    "ax.set_yticks(range(len(combo.index)))\n",
    "ax.set_xticklabels(combo.columns, rotation=45, ha=\"right\")\n",
    "ax.set_yticklabels(combo.index)\n",
    "\n",
    "# gridlines\n",
    "ax.set_xticks([x-0.5 for x in range(1, len(combo.columns))], minor=True)\n",
    "ax.set_yticks([y-0.5 for y in range(1, len(combo.index))], minor=True)\n",
    "ax.grid(which=\"minor\", linestyle=\"-\", linewidth=0.5)\n",
    "ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "# cell labels\n",
    "for i in range(len(combo.index)):\n",
    "    for j in range(len(combo.columns)):\n",
    "        ax.text(j, i, str(combo.iloc[i, j]), ha=\"center\", va=\"center\")\n",
    "\n",
    "plt.title(\"Race × Class Matrix\")\n",
    "plt.colorbar(im, label=\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(HEATMAP_PNG)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba314601",
   "metadata": {},
   "source": [
    "## 6) (Optional) Sessions log merge\n",
    "If `Data/sessions_log.csv` exists (even with a few rows), we can compare **what exists** vs **what’s actually played**.\n",
    "\n",
    "Expected columns in sessions_log.csv:\n",
    "`Date, Player, Campaign, Race, Class, Subclass`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1148f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SESSIONS.exists():\n",
    "    sess = pd.read_csv(SESSIONS)\n",
    "    # normalize keys for join\n",
    "    for c in (\"Race\",\"Class\",\"Subclass\"):\n",
    "        if c in sess.columns:\n",
    "            sess[c] = sess[c].astype(str).str.strip().str.title()\n",
    "\n",
    "    merged = sess.merge(\n",
    "        df_clean[[\"Race\",\"Class\",\"Subclass\"]].drop_duplicates(),\n",
    "        on=[\"Race\",\"Class\",\"Subclass\"],\n",
    "        how=\"left\",\n",
    "        indicator=True\n",
    "    )\n",
    "    display(merged.head())\n",
    "    print(\"Rows matched to reference options:\", int((merged[\"_merge\"]==\"both\").sum()))\n",
    "else:\n",
    "    print(\"No sessions_log.csv found; skipping merge demo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee767a2",
   "metadata": {},
   "source": [
    "## 7) Insights (brief)\n",
    "- Classes with highest counts: see **Class Counts** bar chart.  \n",
    "- Race alignment: heatmap highlights stronger race–class pairings.  \n",
    "- Popularity/Tier (if present as numeric) indicate player preference toward higher-power builds.  \n",
    "- Next steps: expand dataset, analyze subclasses, and incorporate more play-session data for trends over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01edb4d",
   "metadata": {},
   "source": [
    "## 8) Citations / Sources\n",
    "\n",
    "- **Primary data**: Hand-curated for educational purposes, inspired by Dungeons & Dragons 5e reference material.  \n",
    "  - Wizards of the Coast — *Player’s Handbook* (5e).  \n",
    "  - D&D System Reference Document (SRD).  \n",
    "- **Author**: Sean (student, Code:You).\n",
    "\n",
    "> Note: No copyrighted text was copied into the dataset; fields are short labels and categoricals for analysis only.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
